{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "import s3prl.hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/chihyuan/.cache/torch/hub/s3prl_cache/a2b432be9adba2cb59f5cf89a4cf84d5fff8ec3c9fe248ad53349694565ef8c9\n",
      "for https://www.dropbox.com/s/zwsfa6w2iy2cc68/states-500000.ckpt?dl=0\n",
      "[UpstreamExpert] - Using the default upstream expert config\n",
      "UpstreamExpert(\n",
      "  (transformer): PretrainedTransformer(\n",
      "    (extracter): OnlinePreprocessor(\n",
      "      (_melscale): MelScale()\n",
      "      (_mfcc_trans): MFCC(\n",
      "        (amplitude_to_DB): AmplitudeToDB()\n",
      "        (MelSpectrogram): MelSpectrogram(\n",
      "          (spectrogram): Spectrogram()\n",
      "          (mel_scale): MelScale()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (model): TransformerModel(\n",
      "      (input_representations): TransformerInputRepresentations(\n",
      "        (spec_transform): Linear(in_features=80, out_features=768, bias=True)\n",
      "        (LayerNorm): TransformerLayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): TransformerEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "            )\n",
      "          )\n",
      "          (1): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "            )\n",
      "          )\n",
      "          (2): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "            )\n",
      "          )\n",
      "          (3): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "            )\n",
      "          )\n",
      "          (4): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "            )\n",
      "          )\n",
      "          (5): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "            )\n",
      "          )\n",
      "          (6): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "            )\n",
      "          )\n",
      "          (7): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "            )\n",
      "          )\n",
      "          (8): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "            )\n",
      "          )\n",
      "          (9): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "            )\n",
      "          )\n",
      "          (10): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "            )\n",
      "          )\n",
      "          (11): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = getattr(hub, \"mockingjay\")()  # build the Mockingjay model with pre-trained weights\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 's3prl.upstream.mockingjay.builder.PretrainedTransformer'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model.transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3prl import adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADAPTERFUSION_CONFIG_MAP',\n",
       " 'ADAPTER_CACHE',\n",
       " 'ADAPTER_CONFIG_MAP',\n",
       " 'ADAPTER_MODEL_MAPPING',\n",
       " 'AdapterArguments',\n",
       " 'AdapterCompositionBlock',\n",
       " 'AdapterConfig',\n",
       " 'AdapterConfigBase',\n",
       " 'AdapterFusionConfig',\n",
       " 'AdapterInfo',\n",
       " 'AdapterLayer',\n",
       " 'AdapterLayerBase',\n",
       " 'AdapterSetup',\n",
       " 'AdapterType',\n",
       " 'AutoAdapterModel',\n",
       " 'AutoModelWithHeads',\n",
       " 'BartAdapterModel',\n",
       " 'BartModelWithHeads',\n",
       " 'BatchSplit',\n",
       " 'BertAdapterModel',\n",
       " 'BertModelWithHeads',\n",
       " 'CompacterConfig',\n",
       " 'CompacterPlusPlusConfig',\n",
       " 'ConfigUnion',\n",
       " 'DEFAULT_ADAPTERFUSION_CONFIG',\n",
       " 'DEFAULT_ADAPTER_CONFIG',\n",
       " 'DistilBertAdapterModel',\n",
       " 'DistilBertModelWithHeads',\n",
       " 'DynamicAdapterFusionConfig',\n",
       " 'ElectraAdapterModel',\n",
       " 'ElectraModelWithHeads',\n",
       " 'ForwardContext',\n",
       " 'Fuse',\n",
       " 'GPT2AdapterModel',\n",
       " 'GPT2ModelWithHeads',\n",
       " 'HoulsbyConfig',\n",
       " 'HoulsbyInvConfig',\n",
       " 'InvertibleAdaptersMixin',\n",
       " 'MAMConfig',\n",
       " 'MBartAdapterModel',\n",
       " 'MBartModelWithHeads',\n",
       " 'MODEL_WITH_HEADS_MAPPING',\n",
       " 'ModelAdaptersConfig',\n",
       " 'ModelAdaptersMixin',\n",
       " 'ModelWithHeadsAdaptersMixin',\n",
       " 'MultiLingAdapterArguments',\n",
       " 'Parallel',\n",
       " 'ParallelConfig',\n",
       " 'PfeifferConfig',\n",
       " 'PfeifferInvConfig',\n",
       " 'PrefixTuningConfig',\n",
       " 'RobertaAdapterModel',\n",
       " 'RobertaModelWithHeads',\n",
       " 'Split',\n",
       " 'Stack',\n",
       " 'StaticAdapterFusionConfig',\n",
       " 'T5AdapterModel',\n",
       " 'T5ModelWithHeads',\n",
       " 'XLMRobertaAdapterModel',\n",
       " 'XLMRobertaModelWithHeads',\n",
       " '__all__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_class_to_module',\n",
       " '_import_structure',\n",
       " '_modules',\n",
       " '_name',\n",
       " '_objects',\n",
       " 'composition',\n",
       " 'configuration',\n",
       " 'context',\n",
       " 'get_adapter_config_hash',\n",
       " 'get_adapter_info',\n",
       " 'layer',\n",
       " 'list_adapters',\n",
       " 'model_mixin',\n",
       " 'models.auto',\n",
       " 'models.bart',\n",
       " 'models.bert',\n",
       " 'models.distilbert',\n",
       " 'models.electra',\n",
       " 'models.gpt2',\n",
       " 'models.mbart',\n",
       " 'models.roberta',\n",
       " 'models.t5',\n",
       " 'models.xlm_roberta',\n",
       " 'parse_composition',\n",
       " 'training',\n",
       " 'utils',\n",
       " 'validate_composition']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(adapters)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59c55fd4b3978c0def058b870785763f0b3768b417004cdd166463757ca86d4c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Multimodal_Schizo_adapter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
