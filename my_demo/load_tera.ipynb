{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "import s3prl.hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/chihyuan/.cache/torch/hub/s3prl_cache/96e0c8360819d808c1a7046af5dd8a8c62dc30fce5011342c1468f34029f7cbb\n",
      "for https://www.dropbox.com/s/xdoj9wdo87lztv1/states-1000000.ckpt?dl=0\n",
      "[UpstreamExpert] - Using the default upstream expert config\n",
      "UpstreamExpert(\n",
      "  (transformer): PretrainedTransformer(\n",
      "    (extracter): OnlinePreprocessor(\n",
      "      (_melscale): MelScale()\n",
      "      (_mfcc_trans): MFCC(\n",
      "        (amplitude_to_DB): AmplitudeToDB()\n",
      "        (MelSpectrogram): MelSpectrogram(\n",
      "          (spectrogram): Spectrogram()\n",
      "          (mel_scale): MelScale()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (model): TransformerModel(\n",
      "      (shared_parameters): ModuleDict()\n",
      "      (invertible_adapters): ModuleDict()\n",
      "      (input_representations): TransformerInputRepresentations(\n",
      "        (spec_transform): Linear(in_features=80, out_features=768, bias=True)\n",
      "        (LayerNorm): TransformerLayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): TransformerEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (pool): PrefixTuningPool(\n",
      "                    (prefix_tunings): ModuleDict()\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (1): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (pool): PrefixTuningPool(\n",
      "                    (prefix_tunings): ModuleDict()\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (2): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (pool): PrefixTuningPool(\n",
      "                    (prefix_tunings): ModuleDict()\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (prefix_tuning): PrefixTuningPool(\n",
      "        (prefix_tunings): ModuleDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = getattr(hub, \"tera\")()  # build the TERA model with pre-trained weights\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                                                 Param #\n",
       "===============================================================================================\n",
       "UpstreamExpert                                                         --\n",
       "├─PretrainedTransformer: 1-1                                           --\n",
       "│    └─OnlinePreprocessor: 2-1                                         --\n",
       "│    │    └─MelScale: 3-1                                              --\n",
       "│    │    └─MFCC: 3-2                                                  --\n",
       "│    └─TransformerModel: 2-2                                           --\n",
       "│    │    └─ModuleDict: 3-3                                            --\n",
       "│    │    └─ModuleDict: 3-4                                            --\n",
       "│    │    └─TransformerInputRepresentations: 3-5                       63,744\n",
       "│    │    └─TransformerEncoder: 3-6                                    21,263,616\n",
       "│    │    └─PrefixTuningPool: 3-7                                      --\n",
       "===============================================================================================\n",
       "Total params: 21,327,360\n",
       "Trainable params: 21,327,360\n",
       "Non-trainable params: 0\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3prl.upstream.mockingjay.model.TransformerModel"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.transformer.model)  # the model with adpaters' functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerConfig {\n",
       "  \"adapters\": {\n",
       "    \"adapters\": {},\n",
       "    \"config_map\": {},\n",
       "    \"fusion_config_map\": {},\n",
       "    \"fusions\": {}\n",
       "  },\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"model_type\": \"transformer\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"pre_layer_norm\": false,\n",
       "  \"share_layer\": false,\n",
       "  \"transformers_version\": \"4.17.0\"\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UpstreamExpert(\n",
      "  (transformer): PretrainedTransformer(\n",
      "    (extracter): OnlinePreprocessor(\n",
      "      (_melscale): MelScale()\n",
      "      (_mfcc_trans): MFCC(\n",
      "        (amplitude_to_DB): AmplitudeToDB()\n",
      "        (MelSpectrogram): MelSpectrogram(\n",
      "          (spectrogram): Spectrogram()\n",
      "          (mel_scale): MelScale()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (model): TransformerModel(\n",
      "      (shared_parameters): ModuleDict()\n",
      "      (invertible_adapters): ModuleDict()\n",
      "      (input_representations): TransformerInputRepresentations(\n",
      "        (spec_transform): Linear(in_features=80, out_features=768, bias=True)\n",
      "        (LayerNorm): TransformerLayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): TransformerEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict(\n",
      "                    (acu): LoRA()\n",
      "                  )\n",
      "                )\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict(\n",
      "                    (acu): LoRA()\n",
      "                  )\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (pool): PrefixTuningPool(\n",
      "                    (prefix_tunings): ModuleDict()\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (1): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict(\n",
      "                    (acu): LoRA()\n",
      "                  )\n",
      "                )\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict(\n",
      "                    (acu): LoRA()\n",
      "                  )\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (pool): PrefixTuningPool(\n",
      "                    (prefix_tunings): ModuleDict()\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (2): TransformerLayer(\n",
      "            (attention): TransformerAttention(\n",
      "              (self): TransformerSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict(\n",
      "                    (acu): LoRA()\n",
      "                  )\n",
      "                )\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict(\n",
      "                    (acu): LoRA()\n",
      "                  )\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (pool): PrefixTuningPool(\n",
      "                    (prefix_tunings): ModuleDict()\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (output): TransformerSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (LayerNorm): TransformerLayerNorm()\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): TransformerIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (output): TransformerOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): TransformerLayerNorm()\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (prefix_tuning): PrefixTuningPool(\n",
      "        (prefix_tunings): ModuleDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.transformer.model.add_adapter(\"acu\", \"lora\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                                                 Param #\n",
       "===============================================================================================\n",
       "UpstreamExpert                                                         --\n",
       "├─PretrainedTransformer: 1-1                                           --\n",
       "│    └─OnlinePreprocessor: 2-1                                         --\n",
       "│    │    └─MelScale: 3-1                                              --\n",
       "│    │    └─MFCC: 3-2                                                  --\n",
       "│    └─TransformerModel: 2-2                                           --\n",
       "│    │    └─ModuleDict: 3-3                                            --\n",
       "│    │    └─ModuleDict: 3-4                                            --\n",
       "│    │    └─TransformerInputRepresentations: 3-5                       (63,744)\n",
       "│    │    └─TransformerEncoder: 3-6                                    21,337,344\n",
       "│    │    └─PrefixTuningPool: 3-7                                      --\n",
       "===============================================================================================\n",
       "Total params: 17,857,536\n",
       "Trainable params: 73,728\n",
       "Non-trainable params: 17,783,808\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.model.train_adapter(\"acu\")\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type (var_name):depth-idx)                                                     Param #\n",
       "==============================================================================================================\n",
       "UpstreamExpert                                                                        --\n",
       "├─PretrainedTransformer (transformer): 1-1                                            --\n",
       "│    └─OnlinePreprocessor (extracter): 2-1                                            --\n",
       "│    │    └─MelScale (_melscale): 3-1                                                 --\n",
       "│    │    └─MFCC (_mfcc_trans): 3-2                                                   --\n",
       "│    │    │    └─AmplitudeToDB (amplitude_to_DB): 4-1                                 --\n",
       "│    │    │    └─MelSpectrogram (MelSpectrogram): 4-2                                 --\n",
       "│    │    │    │    └─Spectrogram (spectrogram): 5-1                                  --\n",
       "│    │    │    │    └─MelScale (mel_scale): 5-2                                       --\n",
       "│    └─TransformerModel (model): 2-2                                                  --\n",
       "│    │    └─ModuleDict (shared_parameters): 3-3                                       --\n",
       "│    │    └─ModuleDict (invertible_adapters): 3-4                                     --\n",
       "│    │    └─TransformerInputRepresentations (input_representations): 3-5              --\n",
       "│    │    │    └─Linear (spec_transform): 4-3                                         (62,208)\n",
       "│    │    │    └─TransformerLayerNorm (LayerNorm): 4-4                                (1,536)\n",
       "│    │    │    └─Dropout (dropout): 4-5                                               --\n",
       "│    │    └─TransformerEncoder (encoder): 3-6                                         --\n",
       "│    │    │    └─ModuleList (layer): 4-6                                              --\n",
       "│    │    │    │    └─TransformerLayer (0): 5-3                                       --\n",
       "│    │    │    │    │    └─TransformerAttention (attention): 6-1                      --\n",
       "│    │    │    │    │    │    └─TransformerSelfAttention (self): 7-1                  --\n",
       "│    │    │    │    │    │    │    └─Linear (query): 8-1                              --\n",
       "│    │    │    │    │    │    │    │    └─ModuleDict (loras): 9-1                     --\n",
       "│    │    │    │    │    │    │    │    │    └─LoRA (acu): 10-1                       12,288\n",
       "│    │    │    │    │    │    │    └─Linear (key): 8-2                                (590,592)\n",
       "│    │    │    │    │    │    │    └─Linear (value): 8-3                              --\n",
       "│    │    │    │    │    │    │    │    └─ModuleDict (loras): 9-2                     --\n",
       "│    │    │    │    │    │    │    │    │    └─LoRA (acu): 10-2                       12,288\n",
       "│    │    │    │    │    │    │    └─Dropout (dropout): 8-4                           --\n",
       "│    │    │    │    │    │    │    └─PrefixTuningShim (prefix_tuning): 8-5            --\n",
       "│    │    │    │    │    │    │    │    └─PrefixTuningPool (pool): 9-3                --\n",
       "│    │    │    │    │    │    │    │    │    └─ModuleDict (prefix_tunings): 10-3      --\n",
       "│    │    │    │    │    │    └─TransformerSelfOutput (output): 7-2                   --\n",
       "│    │    │    │    │    │    │    └─Linear (dense): 8-6                              (590,592)\n",
       "│    │    │    │    │    │    │    └─Dropout (dropout): 8-7                           --\n",
       "│    │    │    │    │    │    │    └─TransformerLayerNorm (LayerNorm): 8-8            (1,536)\n",
       "│    │    │    │    │    │    │    └─ModuleDict (adapters): 8-9                       --\n",
       "│    │    │    │    │    │    │    └─ModuleDict (adapter_fusion_layer): 8-10          --\n",
       "│    │    │    │    │    └─TransformerIntermediate (intermediate): 6-2                --\n",
       "│    │    │    │    │    │    └─Linear (dense): 7-3                                   (2,362,368)\n",
       "│    │    │    │    │    │    │    └─ModuleDict (loras): 8-11                         --\n",
       "│    │    │    │    │    └─TransformerOutput (output): 6-3                            --\n",
       "│    │    │    │    │    │    └─Linear (dense): 7-4                                   (2,360,064)\n",
       "│    │    │    │    │    │    │    └─ModuleDict (loras): 8-12                         --\n",
       "│    │    │    │    │    │    └─Dropout (dropout): 7-5                                --\n",
       "│    │    │    │    │    │    └─TransformerLayerNorm (LayerNorm): 7-6                 (1,536)\n",
       "│    │    │    │    │    │    └─ModuleDict (adapters): 7-7                            --\n",
       "│    │    │    │    │    │    └─ModuleDict (adapter_fusion_layer): 7-8                --\n",
       "│    │    │    │    └─TransformerLayer (1): 5-4                                       --\n",
       "│    │    │    │    │    └─TransformerAttention (attention): 6-4                      --\n",
       "│    │    │    │    │    │    └─TransformerSelfAttention (self): 7-9                  --\n",
       "│    │    │    │    │    │    │    └─Linear (query): 8-13                             --\n",
       "│    │    │    │    │    │    │    │    └─ModuleDict (loras): 9-4                     --\n",
       "│    │    │    │    │    │    │    │    │    └─LoRA (acu): 10-4                       12,288\n",
       "│    │    │    │    │    │    │    └─Linear (key): 8-14                               (590,592)\n",
       "│    │    │    │    │    │    │    └─Linear (value): 8-15                             --\n",
       "│    │    │    │    │    │    │    │    └─ModuleDict (loras): 9-5                     --\n",
       "│    │    │    │    │    │    │    │    │    └─LoRA (acu): 10-5                       12,288\n",
       "│    │    │    │    │    │    │    └─Dropout (dropout): 8-16                          --\n",
       "│    │    │    │    │    │    │    └─PrefixTuningShim (prefix_tuning): 8-17           --\n",
       "│    │    │    │    │    │    │    │    └─PrefixTuningPool (pool): 9-6                --\n",
       "│    │    │    │    │    │    │    │    │    └─ModuleDict (prefix_tunings): 10-6      --\n",
       "│    │    │    │    │    │    └─TransformerSelfOutput (output): 7-10                  --\n",
       "│    │    │    │    │    │    │    └─Linear (dense): 8-18                             (590,592)\n",
       "│    │    │    │    │    │    │    └─Dropout (dropout): 8-19                          --\n",
       "│    │    │    │    │    │    │    └─TransformerLayerNorm (LayerNorm): 8-20           (1,536)\n",
       "│    │    │    │    │    │    │    └─ModuleDict (adapters): 8-21                      --\n",
       "│    │    │    │    │    │    │    └─ModuleDict (adapter_fusion_layer): 8-22          --\n",
       "│    │    │    │    │    └─TransformerIntermediate (intermediate): 6-5                --\n",
       "│    │    │    │    │    │    └─Linear (dense): 7-11                                  (2,362,368)\n",
       "│    │    │    │    │    │    │    └─ModuleDict (loras): 8-23                         --\n",
       "│    │    │    │    │    └─TransformerOutput (output): 6-6                            --\n",
       "│    │    │    │    │    │    └─Linear (dense): 7-12                                  (2,360,064)\n",
       "│    │    │    │    │    │    │    └─ModuleDict (loras): 8-24                         --\n",
       "│    │    │    │    │    │    └─Dropout (dropout): 7-13                               --\n",
       "│    │    │    │    │    │    └─TransformerLayerNorm (LayerNorm): 7-14                (1,536)\n",
       "│    │    │    │    │    │    └─ModuleDict (adapters): 7-15                           --\n",
       "│    │    │    │    │    │    └─ModuleDict (adapter_fusion_layer): 7-16               --\n",
       "│    │    │    │    └─TransformerLayer (2): 5-5                                       --\n",
       "│    │    │    │    │    └─TransformerAttention (attention): 6-7                      --\n",
       "│    │    │    │    │    │    └─TransformerSelfAttention (self): 7-17                 --\n",
       "│    │    │    │    │    │    │    └─Linear (query): 8-25                             --\n",
       "│    │    │    │    │    │    │    │    └─ModuleDict (loras): 9-7                     --\n",
       "│    │    │    │    │    │    │    │    │    └─LoRA (acu): 10-7                       12,288\n",
       "│    │    │    │    │    │    │    └─Linear (key): 8-26                               (590,592)\n",
       "│    │    │    │    │    │    │    └─Linear (value): 8-27                             --\n",
       "│    │    │    │    │    │    │    │    └─ModuleDict (loras): 9-8                     --\n",
       "│    │    │    │    │    │    │    │    │    └─LoRA (acu): 10-8                       12,288\n",
       "│    │    │    │    │    │    │    └─Dropout (dropout): 8-28                          --\n",
       "│    │    │    │    │    │    │    └─PrefixTuningShim (prefix_tuning): 8-29           --\n",
       "│    │    │    │    │    │    │    │    └─PrefixTuningPool (pool): 9-9                --\n",
       "│    │    │    │    │    │    │    │    │    └─ModuleDict (prefix_tunings): 10-9      --\n",
       "│    │    │    │    │    │    └─TransformerSelfOutput (output): 7-18                  --\n",
       "│    │    │    │    │    │    │    └─Linear (dense): 8-30                             (590,592)\n",
       "│    │    │    │    │    │    │    └─Dropout (dropout): 8-31                          --\n",
       "│    │    │    │    │    │    │    └─TransformerLayerNorm (LayerNorm): 8-32           (1,536)\n",
       "│    │    │    │    │    │    │    └─ModuleDict (adapters): 8-33                      --\n",
       "│    │    │    │    │    │    │    └─ModuleDict (adapter_fusion_layer): 8-34          --\n",
       "│    │    │    │    │    └─TransformerIntermediate (intermediate): 6-8                --\n",
       "│    │    │    │    │    │    └─Linear (dense): 7-19                                  (2,362,368)\n",
       "│    │    │    │    │    │    │    └─ModuleDict (loras): 8-35                         --\n",
       "│    │    │    │    │    └─TransformerOutput (output): 6-9                            --\n",
       "│    │    │    │    │    │    └─Linear (dense): 7-20                                  (2,360,064)\n",
       "│    │    │    │    │    │    │    └─ModuleDict (loras): 8-36                         --\n",
       "│    │    │    │    │    │    └─Dropout (dropout): 7-21                               --\n",
       "│    │    │    │    │    │    └─TransformerLayerNorm (LayerNorm): 7-22                (1,536)\n",
       "│    │    │    │    │    │    └─ModuleDict (adapters): 7-23                           --\n",
       "│    │    │    │    │    │    └─ModuleDict (adapter_fusion_layer): 7-24               --\n",
       "│    │    └─PrefixTuningPool (prefix_tuning): 3-7                                     --\n",
       "│    │    │    └─ModuleDict (prefix_tunings): 4-7                                     --\n",
       "==============================================================================================================\n",
       "Total params: 17,857,536\n",
       "Trainable params: 73,728\n",
       "Non-trainable params: 17,783,808\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, depth=20, row_settings=[\"depth\", \"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Psuedo Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stack[acu]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.model.active_adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_hidden_state': tensor([[[-0.0772,  0.1864, -0.1726,  ...,  0.0657, -0.4511,  0.6702],\n",
      "         [ 0.0217,  0.1596, -0.1643,  ..., -0.3044, -0.2634,  0.7669],\n",
      "         [ 0.0647,  0.2621, -0.2537,  ..., -0.2939, -0.2514,  0.4612],\n",
      "         ...,\n",
      "         [-0.0192,  0.0971, -0.1113,  ..., -0.3518, -0.3453,  0.6550],\n",
      "         [ 0.0911,  0.2704, -0.0469,  ..., -0.4236, -0.2951,  0.7091],\n",
      "         [-0.0363,  0.2406, -0.2056,  ..., -0.2235, -0.3272,  0.6734]],\n",
      "\n",
      "        [[-0.0332,  0.2785, -0.0066,  ..., -0.3213, -0.3547,  0.7663],\n",
      "         [-0.0694,  0.1105, -0.1702,  ..., -0.3618, -0.3082,  0.6899],\n",
      "         [ 0.1156,  0.1406, -0.0776,  ..., -0.3099, -0.3621,  0.2525],\n",
      "         ...,\n",
      "         [-0.0385,  0.0461, -0.0262,  ..., -0.3229, -0.2217,  0.6997],\n",
      "         [-0.1039,  0.1706, -0.0059,  ..., -0.3928, -0.2670,  0.7557],\n",
      "         [-0.0702,  0.2806, -0.0604,  ..., -0.3823, -0.2598,  0.7267]],\n",
      "\n",
      "        [[ 0.0136,  0.1547, -0.2302,  ..., -0.1992, -0.3561,  0.7864],\n",
      "         [-0.0333,  0.0012, -0.0194,  ..., -0.3396, -0.1961,  0.6354],\n",
      "         [-0.0295,  0.0426, -0.0599,  ..., -0.2451, -0.2974,  0.6433],\n",
      "         ...,\n",
      "         [ 0.0176,  0.0062, -0.1474,  ..., -0.2958, -0.2518,  0.3782],\n",
      "         [-0.0848,  0.2446, -0.0334,  ..., -0.2516, -0.1485,  0.6700],\n",
      "         [ 0.0040,  0.0193, -0.0730,  ..., -0.2212, -0.2574,  0.1895]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0192,  0.2901, -0.1146,  ..., -0.3015, -0.3260,  0.7990],\n",
      "         [ 0.0806,  0.2062, -0.3026,  ..., -0.3041, -0.3090,  0.7021],\n",
      "         [ 0.0589,  0.1780, -0.2750,  ..., -0.3984, -0.2975,  0.7742],\n",
      "         ...,\n",
      "         [ 0.0335,  0.1007, -0.2864,  ..., -0.3519, -0.3606,  0.8198],\n",
      "         [ 0.0083,  0.2043, -0.1104,  ..., -0.2669, -0.2892,  0.6252],\n",
      "         [ 0.0429,  0.1729, -0.2237,  ..., -0.3632, -0.3081,  0.6930]],\n",
      "\n",
      "        [[-0.0991,  0.0387, -0.2212,  ..., -0.2967, -0.1433,  0.6568],\n",
      "         [ 0.0407,  0.0506, -0.1333,  ..., -0.2950, -0.2407,  0.6963],\n",
      "         [-0.0800, -0.0034, -0.2080,  ..., -0.2745, -0.2889,  0.1968],\n",
      "         ...,\n",
      "         [-0.0054,  0.0797, -0.1160,  ..., -0.3305, -0.4292,  0.4916],\n",
      "         [-0.0600,  0.1007, -0.2118,  ..., -0.2760, -0.4130,  0.6896],\n",
      "         [-0.0257,  0.0882, -0.0945,  ..., -0.3935, -0.1744,  0.6682]],\n",
      "\n",
      "        [[ 0.0272,  0.1259, -0.0816,  ..., -0.3619, -0.3265,  0.6629],\n",
      "         [-0.0936,  0.1383, -0.2410,  ..., -0.2168, -0.3503,  0.5989],\n",
      "         [ 0.0219,  0.1052, -0.0902,  ..., -0.3891, -0.3139,  0.7702],\n",
      "         ...,\n",
      "         [ 0.0771,  0.1426, -0.1716,  ..., -0.2546, -0.2926,  0.7046],\n",
      "         [-0.0244,  0.1787, -0.0774,  ..., -0.3651, -0.3448,  0.7297],\n",
      "         [-0.1149,  0.1066, -0.0766,  ..., -0.4862, -0.3582,  0.6568]]]), 'hidden_states': (tensor([[[ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0000, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.0000,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         ...,\n",
      "         [ 0.4111,  0.2877,  0.1067,  ..., -2.4160, -0.0000, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -0.0000],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -0.0000, -0.0143, -1.4341]],\n",
      "\n",
      "        [[ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -0.0000],\n",
      "         ...,\n",
      "         [ 0.4111,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341]],\n",
      "\n",
      "        [[ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.0000,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -0.0000, -0.0143, -1.4341],\n",
      "         ...,\n",
      "         [ 0.4111,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -0.0000, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         ...,\n",
      "         [ 0.4111,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.0000,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341]],\n",
      "\n",
      "        [[ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         ...,\n",
      "         [ 0.4111,  0.0000,  0.0000,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.0000,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -0.0000],\n",
      "         [ 0.0000,  0.0000,  0.1067,  ..., -2.4160, -0.0143, -1.4341]],\n",
      "\n",
      "        [[ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0000, -1.4341],\n",
      "         ...,\n",
      "         [ 0.4111,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -0.0000],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341],\n",
      "         [ 0.4112,  0.2877,  0.1067,  ..., -2.4160, -0.0143, -1.4341]]]), tensor([[[-2.9127e-02, -7.4099e-02, -4.6371e-01,  ..., -6.2670e-01,\n",
      "          -5.2470e-02,  2.3437e-01],\n",
      "         [ 1.3543e+00, -3.8777e-01, -4.5666e-01,  ..., -6.3272e-01,\n",
      "           3.4041e-01,  4.9558e-01],\n",
      "         [ 1.4544e+00, -2.4886e-01, -2.0291e-01,  ..., -6.7201e-01,\n",
      "           1.3724e-01,  6.8837e-01],\n",
      "         ...,\n",
      "         [ 1.4158e+00, -3.8471e-01, -4.3261e-01,  ..., -6.3125e-01,\n",
      "           4.3755e-02,  7.3372e-01],\n",
      "         [ 1.5007e+00, -4.0508e-01, -2.4322e-01,  ..., -8.6199e-01,\n",
      "           9.2362e-02,  7.2570e-01],\n",
      "         [ 1.4745e+00, -4.2675e-01, -4.8045e-01,  ..., -5.4620e-01,\n",
      "           1.7852e-01,  2.7517e-01]],\n",
      "\n",
      "        [[ 1.3600e+00, -3.7053e-01, -4.9711e-01,  ..., -6.1293e-01,\n",
      "           9.6475e-02,  3.9451e-01],\n",
      "         [ 1.5769e+00, -7.6620e-02, -3.1547e-01,  ..., -4.6630e-01,\n",
      "           2.4621e-03,  2.3562e-01],\n",
      "         [ 1.4418e+00, -4.1226e-01, -3.0577e-01,  ..., -5.9703e-01,\n",
      "           1.7502e-01,  5.9682e-01],\n",
      "         ...,\n",
      "         [ 1.6912e+00, -3.5698e-01, -4.1435e-01,  ..., -5.6323e-01,\n",
      "           2.8435e-01,  3.6368e-01],\n",
      "         [ 1.9744e-01, -3.6911e-01, -4.2602e-01,  ..., -5.3334e-01,\n",
      "           2.0079e-01,  4.6371e-01],\n",
      "         [ 1.5287e+00, -3.6508e-01, -3.8813e-01,  ..., -7.9732e-01,\n",
      "           1.6525e-01,  6.4736e-01]],\n",
      "\n",
      "        [[ 1.1969e+00, -4.0796e-01, -2.2564e-01,  ..., -5.4282e-01,\n",
      "           1.5568e-01,  3.1932e-01],\n",
      "         [ 1.3838e+00, -3.6502e-01, -4.4649e-01,  ..., -5.1862e-01,\n",
      "           4.6147e-01,  4.6069e-01],\n",
      "         [ 1.3464e-02, -3.9196e-01, -3.0421e-01,  ..., -1.6637e-01,\n",
      "           1.4057e-01, -1.4764e-01],\n",
      "         ...,\n",
      "         [ 1.5157e+00, -3.9694e-01, -3.3716e-01,  ..., -7.3202e-01,\n",
      "           2.2265e-01, -1.3424e-01],\n",
      "         [-9.9306e-02, -3.4882e-01, -1.6759e-01,  ..., -5.3945e-01,\n",
      "           4.5459e-01,  3.8246e-01],\n",
      "         [ 1.2630e+00, -4.2671e-01, -6.2781e-01,  ..., -1.4356e-04,\n",
      "           4.5019e-02,  4.3451e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5091e+00, -3.3382e-01, -3.1687e-01,  ..., -9.8957e-04,\n",
      "           5.9094e-02,  5.7798e-01],\n",
      "         [ 1.1014e+00, -3.6146e-01, -5.8880e-01,  ..., -7.2696e-01,\n",
      "           1.0718e-01,  7.2030e-01],\n",
      "         [ 1.6995e+00, -4.1726e-01, -4.7058e-01,  ..., -5.4970e-01,\n",
      "           1.3474e-01,  3.6250e-01],\n",
      "         ...,\n",
      "         [ 1.3465e+00, -4.1126e-01, -9.1003e-02,  ..., -6.1931e-01,\n",
      "           2.3556e-01,  2.6207e-01],\n",
      "         [ 1.5498e+00, -3.0945e-01, -2.1543e-01,  ..., -5.6206e-01,\n",
      "          -8.0161e-03,  3.9045e-01],\n",
      "         [ 1.3170e+00, -4.1456e-01, -2.9346e-01,  ..., -1.0156e+00,\n",
      "           6.3868e-02,  4.9327e-01]],\n",
      "\n",
      "        [[ 1.6250e+00, -3.4771e-01, -1.9558e-01,  ..., -3.7201e-01,\n",
      "           2.3298e-01,  3.7717e-01],\n",
      "         [ 1.4782e+00, -3.9937e-01, -3.8393e-01,  ..., -5.4233e-01,\n",
      "           9.9423e-02,  4.1737e-01],\n",
      "         [ 1.4959e+00, -3.6031e-01, -4.3108e-01,  ..., -7.9812e-01,\n",
      "           1.7332e-01,  3.5884e-01],\n",
      "         ...,\n",
      "         [ 1.4626e+00, -3.7817e-01, -3.6712e-01,  ..., -7.7334e-01,\n",
      "           5.2458e-02,  8.7666e-01],\n",
      "         [ 1.2674e+00, -4.4714e-01, -6.2396e-01,  ..., -8.6777e-01,\n",
      "           2.2320e-02,  7.0724e-01],\n",
      "         [ 1.6748e+00, -2.9715e-01, -3.0294e-01,  ..., -7.9288e-01,\n",
      "           2.1118e-01,  4.3939e-01]],\n",
      "\n",
      "        [[ 1.2727e+00, -4.0961e-01, -3.8236e-01,  ..., -8.2237e-04,\n",
      "           1.5031e-01, -1.5153e-01],\n",
      "         [ 1.3856e+00, -3.2735e-01, -3.0884e-01,  ..., -5.5892e-01,\n",
      "           2.3349e-01,  6.8482e-01],\n",
      "         [ 1.4502e+00, -4.0190e-01, -6.9163e-01,  ..., -7.9605e-01,\n",
      "           1.9608e-01,  5.1981e-01],\n",
      "         ...,\n",
      "         [ 1.4817e+00, -3.7203e-01, -1.1715e-01,  ..., -6.5041e-01,\n",
      "           1.3493e-01,  4.4533e-02],\n",
      "         [ 1.8371e+00, -3.5292e-01,  4.0351e-03,  ..., -2.6977e-01,\n",
      "           1.7185e-01,  4.2023e-01],\n",
      "         [ 1.3871e+00, -6.6292e-02, -6.9423e-01,  ..., -9.4233e-01,\n",
      "           2.1254e-01,  5.3994e-01]]]), tensor([[[-2.2967e-02,  6.3739e-02, -1.3165e-01,  ..., -5.7932e-03,\n",
      "          -1.7708e-01, -3.3808e-01],\n",
      "         [ 5.7126e-01, -1.5439e-01, -6.4859e-02,  ..., -1.4314e-01,\n",
      "           1.3409e-01, -2.6715e-01],\n",
      "         [ 5.0420e-01,  4.9488e-02, -2.2509e-01,  ..., -1.6987e-01,\n",
      "           1.8333e-02, -1.3877e-01],\n",
      "         ...,\n",
      "         [ 3.9106e-01, -2.4762e-01, -1.5282e-01,  ..., -6.2883e-02,\n",
      "          -6.0232e-02, -2.2494e-01],\n",
      "         [ 4.8516e-01, -5.6177e-02,  8.7913e-02,  ..., -6.4919e-01,\n",
      "          -9.9812e-04, -2.5993e-02],\n",
      "         [ 3.5469e-01, -3.6406e-02, -1.0162e-01,  ...,  4.4067e-01,\n",
      "          -7.4279e-02, -3.4408e-01]],\n",
      "\n",
      "        [[ 3.2647e-01,  6.3920e-02, -9.8766e-02,  ..., -9.8193e-02,\n",
      "          -1.1336e-01, -1.3352e-01],\n",
      "         [ 3.2865e-01, -3.3622e-02, -2.8627e-02,  ..., -4.4272e-01,\n",
      "          -1.5575e-01, -2.8242e-01],\n",
      "         [ 6.0053e-01, -1.0776e-01, -1.1783e-01,  ...,  2.0503e-01,\n",
      "          -3.4610e-02, -4.1770e-02],\n",
      "         ...,\n",
      "         [ 4.9826e-01, -9.0715e-02, -2.1337e-02,  ...,  6.8076e-02,\n",
      "           9.1580e-02, -1.7023e-01],\n",
      "         [ 1.9522e-01,  8.0970e-02, -1.7789e-01,  ...,  5.3096e-02,\n",
      "          -8.5502e-03, -1.7854e-01],\n",
      "         [ 4.2312e-01, -3.7041e-02, -1.7356e-02,  ..., -3.9138e-02,\n",
      "          -3.5536e-03, -1.2999e-01]],\n",
      "\n",
      "        [[ 3.5431e-01, -7.1030e-02, -1.4799e-02,  ...,  4.2940e-01,\n",
      "          -1.0805e-01, -1.8959e-01],\n",
      "         [ 3.2691e-01, -9.3864e-02, -2.1483e-01,  ...,  1.1283e-01,\n",
      "           1.7129e-01, -1.3803e-01],\n",
      "         [-6.5458e-02, -1.1165e-01,  6.7100e-02,  ..., -1.0622e-02,\n",
      "           1.4072e-02, -4.4976e-01],\n",
      "         ...,\n",
      "         [ 3.8619e-01,  5.3882e-02,  2.6211e-02,  ..., -6.2834e-02,\n",
      "           5.7298e-02, -4.7913e-01],\n",
      "         [-4.0835e-02,  8.6643e-02,  1.0223e-01,  ..., -3.3970e-02,\n",
      "           1.3211e-01, -3.7651e-01],\n",
      "         [ 4.0734e-01, -4.8804e-02, -1.5643e-01,  ...,  3.1866e-01,\n",
      "          -7.4404e-02, -7.8065e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.4485e-01, -2.7988e-02, -2.1311e-02,  ...,  2.3994e-01,\n",
      "          -5.3497e-02, -1.8441e-01],\n",
      "         [ 2.7801e-01, -2.2859e-01, -2.8536e-02,  ..., -1.9340e-02,\n",
      "          -1.0052e-01, -2.5281e-01],\n",
      "         [ 6.3509e-01, -1.2052e-01, -1.1863e-01,  ...,  8.3050e-03,\n",
      "          -8.6213e-02,  8.0683e-03],\n",
      "         ...,\n",
      "         [ 4.7252e-01, -1.1777e-01, -1.8347e-01,  ...,  2.6159e-04,\n",
      "          -7.2392e-02, -9.9068e-02],\n",
      "         [ 4.1615e-01, -2.6926e-01,  1.2893e-01,  ...,  1.3280e-02,\n",
      "          -8.8614e-02, -1.8147e-01],\n",
      "         [ 4.0260e-01, -6.9621e-02, -5.3876e-02,  ..., -2.8210e-01,\n",
      "          -8.4145e-02, -3.3337e-01]],\n",
      "\n",
      "        [[ 3.9466e-01,  3.1118e-02, -6.9731e-02,  ...,  5.1632e-02,\n",
      "           1.4943e-01, -2.7170e-01],\n",
      "         [ 3.6066e-01, -1.8340e-02, -6.7172e-02,  ...,  1.0706e-01,\n",
      "          -2.6547e-02, -1.3810e-02],\n",
      "         [ 3.8019e-01, -1.4574e-02, -3.4395e-02,  ...,  5.3760e-02,\n",
      "          -4.1945e-02, -9.5496e-02],\n",
      "         ...,\n",
      "         [ 4.5000e-01, -1.4550e-01, -1.2954e-01,  ...,  1.8104e-02,\n",
      "          -1.6150e-01,  5.1315e-02],\n",
      "         [ 3.4573e-01,  7.9371e-02, -1.4486e-01,  ..., -1.1561e-01,\n",
      "          -1.5624e-01, -3.3876e-03],\n",
      "         [ 5.7091e-01,  4.0405e-02,  1.0102e-01,  ..., -1.1838e-02,\n",
      "           1.4252e-01, -3.5549e-01]],\n",
      "\n",
      "        [[ 3.0948e-01, -7.8221e-02, -1.2274e-01,  ...,  9.5690e-02,\n",
      "          -7.5975e-02, -4.6340e-01],\n",
      "         [ 3.6218e-01, -5.6865e-02, -1.4189e-01,  ...,  4.3054e-01,\n",
      "          -1.3232e-02, -2.0502e-01],\n",
      "         [ 4.3499e-01, -8.2388e-02, -1.4613e-01,  ..., -3.0945e-02,\n",
      "           2.3717e-02, -4.7448e-02],\n",
      "         ...,\n",
      "         [ 5.5032e-01,  8.6727e-02, -8.1549e-02,  ...,  9.4317e-03,\n",
      "          -4.9559e-02, -3.7340e-01],\n",
      "         [ 4.8957e-01, -5.6144e-02, -3.7779e-02,  ...,  7.8096e-02,\n",
      "          -6.4877e-03, -1.7749e-01],\n",
      "         [ 3.9778e-01,  2.5478e-03, -1.4568e-01,  ..., -5.2702e-01,\n",
      "          -1.4026e-01, -2.9372e-01]]]), tensor([[[-0.0772,  0.1864, -0.1726,  ...,  0.0657, -0.4511,  0.6702],\n",
      "         [ 0.0217,  0.1596, -0.1643,  ..., -0.3044, -0.2634,  0.7669],\n",
      "         [ 0.0647,  0.2621, -0.2537,  ..., -0.2939, -0.2514,  0.4612],\n",
      "         ...,\n",
      "         [-0.0192,  0.0971, -0.1113,  ..., -0.3518, -0.3453,  0.6550],\n",
      "         [ 0.0911,  0.2704, -0.0469,  ..., -0.4236, -0.2951,  0.7091],\n",
      "         [-0.0363,  0.2406, -0.2056,  ..., -0.2235, -0.3272,  0.6734]],\n",
      "\n",
      "        [[-0.0332,  0.2785, -0.0066,  ..., -0.3213, -0.3547,  0.7663],\n",
      "         [-0.0694,  0.1105, -0.1702,  ..., -0.3618, -0.3082,  0.6899],\n",
      "         [ 0.1156,  0.1406, -0.0776,  ..., -0.3099, -0.3621,  0.2525],\n",
      "         ...,\n",
      "         [-0.0385,  0.0461, -0.0262,  ..., -0.3229, -0.2217,  0.6997],\n",
      "         [-0.1039,  0.1706, -0.0059,  ..., -0.3928, -0.2670,  0.7557],\n",
      "         [-0.0702,  0.2806, -0.0604,  ..., -0.3823, -0.2598,  0.7267]],\n",
      "\n",
      "        [[ 0.0136,  0.1547, -0.2302,  ..., -0.1992, -0.3561,  0.7864],\n",
      "         [-0.0333,  0.0012, -0.0194,  ..., -0.3396, -0.1961,  0.6354],\n",
      "         [-0.0295,  0.0426, -0.0599,  ..., -0.2451, -0.2974,  0.6433],\n",
      "         ...,\n",
      "         [ 0.0176,  0.0062, -0.1474,  ..., -0.2958, -0.2518,  0.3782],\n",
      "         [-0.0848,  0.2446, -0.0334,  ..., -0.2516, -0.1485,  0.6700],\n",
      "         [ 0.0040,  0.0193, -0.0730,  ..., -0.2212, -0.2574,  0.1895]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0192,  0.2901, -0.1146,  ..., -0.3015, -0.3260,  0.7990],\n",
      "         [ 0.0806,  0.2062, -0.3026,  ..., -0.3041, -0.3090,  0.7021],\n",
      "         [ 0.0589,  0.1780, -0.2750,  ..., -0.3984, -0.2975,  0.7742],\n",
      "         ...,\n",
      "         [ 0.0335,  0.1007, -0.2864,  ..., -0.3519, -0.3606,  0.8198],\n",
      "         [ 0.0083,  0.2043, -0.1104,  ..., -0.2669, -0.2892,  0.6252],\n",
      "         [ 0.0429,  0.1729, -0.2237,  ..., -0.3632, -0.3081,  0.6930]],\n",
      "\n",
      "        [[-0.0991,  0.0387, -0.2212,  ..., -0.2967, -0.1433,  0.6568],\n",
      "         [ 0.0407,  0.0506, -0.1333,  ..., -0.2950, -0.2407,  0.6963],\n",
      "         [-0.0800, -0.0034, -0.2080,  ..., -0.2745, -0.2889,  0.1968],\n",
      "         ...,\n",
      "         [-0.0054,  0.0797, -0.1160,  ..., -0.3305, -0.4292,  0.4916],\n",
      "         [-0.0600,  0.1007, -0.2118,  ..., -0.2760, -0.4130,  0.6896],\n",
      "         [-0.0257,  0.0882, -0.0945,  ..., -0.3935, -0.1744,  0.6682]],\n",
      "\n",
      "        [[ 0.0272,  0.1259, -0.0816,  ..., -0.3619, -0.3265,  0.6629],\n",
      "         [-0.0936,  0.1383, -0.2410,  ..., -0.2168, -0.3503,  0.5989],\n",
      "         [ 0.0219,  0.1052, -0.0902,  ..., -0.3891, -0.3139,  0.7702],\n",
      "         ...,\n",
      "         [ 0.0771,  0.1426, -0.1716,  ..., -0.2546, -0.2926,  0.7046],\n",
      "         [-0.0244,  0.1787, -0.0774,  ..., -0.3651, -0.3448,  0.7297],\n",
      "         [-0.1149,  0.1066, -0.0766,  ..., -0.4862, -0.3582,  0.6568]]]))}\n"
     ]
    }
   ],
   "source": [
    "# model.transformer.model.add_adapter(\"acu\", \"pfeiffer\")  # Before activated, resul is the same as original mockingjay in original s3prl\n",
    "wavs = [torch.ones(160000, dtype=torch.float) for _ in range(16)]\n",
    "model.train()  # will have random effect\n",
    "# model.eval()\n",
    "with torch.no_grad():\n",
    "    print(model(wavs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_hidden_state': tensor([[[-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         ...,\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101]],\n",
      "\n",
      "        [[-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         ...,\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101]],\n",
      "\n",
      "        [[-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         ...,\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         ...,\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101]],\n",
      "\n",
      "        [[-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         ...,\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101]],\n",
      "\n",
      "        [[-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         ...,\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101]]]), 'hidden_states': (tensor([[[ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         ...,\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907]],\n",
      "\n",
      "        [[ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         ...,\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907]],\n",
      "\n",
      "        [[ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         ...,\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         ...,\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907]],\n",
      "\n",
      "        [[ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         ...,\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907]],\n",
      "\n",
      "        [[ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         ...,\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907],\n",
      "         [ 0.3700,  0.2589,  0.0960,  ..., -2.1744, -0.0129, -1.2907]]]), tensor([[[ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         ...,\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443]],\n",
      "\n",
      "        [[ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         ...,\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443]],\n",
      "\n",
      "        [[ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         ...,\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         ...,\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443]],\n",
      "\n",
      "        [[ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         ...,\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443]],\n",
      "\n",
      "        [[ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         ...,\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443],\n",
      "         [ 1.4060, -0.3810, -0.4808,  ..., -0.6305,  0.1964,  0.4443]]]), tensor([[[ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         ...,\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184]],\n",
      "\n",
      "        [[ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         ...,\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184]],\n",
      "\n",
      "        [[ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         ...,\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         ...,\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184]],\n",
      "\n",
      "        [[ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         ...,\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184]],\n",
      "\n",
      "        [[ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         ...,\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184],\n",
      "         [ 0.4308,  0.0110, -0.1836,  ...,  0.0163, -0.0552, -0.3184]]]), tensor([[[-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         ...,\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101]],\n",
      "\n",
      "        [[-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         ...,\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101]],\n",
      "\n",
      "        [[-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         ...,\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         ...,\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101]],\n",
      "\n",
      "        [[-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         ...,\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101]],\n",
      "\n",
      "        [[-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         ...,\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101],\n",
      "         [-0.0130,  0.0918, -0.1565,  ..., -0.3166, -0.3251,  0.6101]]]))}\n"
     ]
    }
   ],
   "source": [
    "model.transformer.model.delete_adapter(\"acu\")\n",
    "# model.transformer.model.add_adapter(\"acu\", \"pfeiffer\")  # Before activated, resul is the same as original mockingjay in original s3prl\n",
    "wavs = [torch.ones(160000, dtype=torch.float) for _ in range(16)]\n",
    "# model.train()  # will have random effect\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(model(wavs))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59c55fd4b3978c0def058b870785763f0b3768b417004cdd166463757ca86d4c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Multimodal_Schizo_adapter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
